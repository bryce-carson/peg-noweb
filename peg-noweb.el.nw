\documentclass{article}

\usepackage{hyperref}
\usepackage{biblatex}
\usepackage{noweb}

\newcommand{\whyse}{\textsc{WHYSE}}

\begin{document}

\begin{abstract}
  The first official release of \whyse{} isn't planned to utilize PEG parsing in
  any of its features, but the PEG parser implemented in this Emacs package was
  developed early, before considering using Ref\TeX{} and AUC\TeX{} as a basis
  for implementing things like navigation, croff-reference management, table of
  contents, label browsing, etc.

  The \textsc{peg} package for \textsc{Emacs} provides automatic parser
  generation from a formal PEG grammar. The grammar for noweb used in this
  package is based off of the description of \emph{the tool syntax} given in the
  \cite[Noweb Hacker's Guide]{ramsey1992}.

  Every character of an input text to be parsed by parsing expressions in a PEG
  must be defined in terminal rules of the formal grammar.
  %% NOTE: to match the new line character in a text stream, the string literal
  %% "\n" must be included. The (eol) PEG rule /tests/ for the end of line by
  %% guarding against unintended evaluation of the boolean return value of the
  %% standard Emacs Lisp (eolp). To test if point is at the end of a line, use
  %% (eol); to match the end of line, and permit parsing the next line of input,
  %% include the string literal "\n".
  The root rule in the grammar for Noweb tool syntax is named [[noweb]], so with
  [[<<PEG rules>>]] in scope a match using the root rule [[noweb]] is attempted
  against the current buffer. The current buffer must contain the tool syntax
  produced by \texttt{noweave} and passed to any one of the default or
  additional filters specified on the command line.

  To further the development of \whyse{}, packaging [[<<PEG rules>>]] as an
  independent peg package extension allows me to forget about this subproject
  while I focus on Ref\TeX{} and AUC\TeX{} as foundational layers for
  implementing \whyse{}.

  Writing a useful pulic interface to the parse tree before continuing on any
  other adventure in WHYSE-land may help me complete this subproject, at least.
  It would also allow me to utilize any parse tree more effectively.
\end{abstract}

\section{The \textit{PEG Noweb} Emacs Package}
\label{sec:pkg-meta}

<<peg-noweb.el>>=
;;; peg-noweb.el --- PEG ruleset for the Noweb Tool Syntax -*- lexical-binding: t -*-

;; Copyright Â© 2025 Bryce Carson

;; Author: Bryce Carson <bryce.a.carson@gmail.com>
;; Version: 0.1
;; Package-Requires: ((peg "1.0.1"))
;; Keywords: tools, tex, hypermedia, peg
;; URL: https://github.com/bryce-carson/peg-noweb

;; This file is not part of GNU Emacs.

<<Licensing and copyright>>

;;; Commentary:
;; This file defines a PEG ruleset for Noweb's tool syntax, which is used to
;; extend Noweb with UNIX tools like AWK or sed.

;;; Code:
<<code>>

(provide 'peg-noweb)

;; Local Variables:
;; mode: emacs-lisp
;; no-byte-compile: t
;; no-native-compile: t
;; End:
@

\subsection{Licensing and Copyright}
\label{sec:pkg-license}

This subsection contains licensing and copyright information for PEG Noweb, and
any relevant third-party copyright notices.

<<Licensing and copyright>>=
;; This program is free software: you can redistribute it and/or
;; modify it under the terms of the GNU General Public License as
;; published by the Free Software Foundation, either version 3 of the
;; License, or (at your option) any later version.

;; This program is distributed in the hope that it will be useful, but
;; WITHOUT ANY WARRANTY; without even the implied warranty of
;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
;; General Public License for more details.

;; You should have received a copy of the GNU General Public License
;; along with this program. If not, see
;; <https://www.gnu.org/licenses/>.
@

\subsection{Package Code}
\label{sec:pkg-code}

All package code will be included in the [[<<code>>]] module. At first the only
code included in the package will be the [[noweb]] PEG ruleset, because that is
complete. A public API for the interacting with the ruleset and texts which
should match the grammar it defines will be defined after the set of rules.

<<code>>=
<<PEG rules>>

(define-peg-ruleset noweb-markup
  '(noweb

    nl
    !eol
    spc

    file
    path
    path-component
    path-separator
    file-name

    chunk
    begin
    end-of-defun-function
    ordinal
    kind
    chunk-contents

    text
    nwnl

    defn
    use

    quotation

    line
    language

    idx
    xr

    i-define-or-use

    i-definitions
    i-isused
    i-defitem

    i-usages
    i-isdefined
    i-useitem

    i-identifiers
    i-entry
    i-entrydefn
    i-entryuse

    i-localdefn
    i-nl

    x-label
    x-ref
    x-undefined
    x-prev-or-next-def

    x-continued-definitions-of-the-current-chunk
    x-usages

    x-notused
    x-chunks
    x-chunk

    x-tag
    label

    header
    trailer
    fatal))

@ 

\section{Public Interface}
\label{sec:pkg-interface}

The public interface of the package should include some basic programming
facilities, otherwise it would be difficult to program any application with the
only the ruleset. In pursuit of that, I'll endure the difficulty and any
advances I make will become part of the public interface before I take
suggestions.

Before I suffer well the difficulty of learning what a useful interface to a
packaged PEG
ruleset and the result of parsing a text which matches the root rule [[noweb]]
I will conduct some research to see what interfaces to PEG grammars are
typically provided.

There should some input and output functionality at least: a text in a buffer
must be supplied to the function \texttt{with-peg-rules}. A function to do this
doesn't need to be packaged, but would be convenient.

Adapted from \texttt{lm-with-file} from \texttt{lisp-mnt.el},
I provide \texttt{peg-noweb-with-file}.
The file argument is the file which will be passed to nomarkup,
and the output is captured by Emacs.

To utilze nomarkup the customization variable peg-noweb-filter-path must be set,
otherwise the default value will come from parsing the output of noweave, which
must be on the path.

<<code>>=
(defgroup peg-noweb ()
  "Customization Variables affecting PEG Noweb, the peg package extension library providing a ruleset for the Noweb tool syntax.")

(defcustom peg-noweb-filter-directory
  (and (= 0 (shell-command "which noweave"))
       (with-temp-buffer (shell-command "noweave -v -n" (get-buffer (current-buffer)))
                         (file-name-directory (buffer-substring (goto-line 3) (- (point-at-eol) 2)))))
  "The directory containing Noweb filters, which also contains the executable `markup' in particular."
  :group 'peg-noweb)

;; FIXME: the current parse tree contains a `nil' after the chunk type
;; and number assoc, and that needs to be analyzed. Why is this `nil' in
;; the stack? I assume and believe it is because of the collapsing of
;; stringy tokens; when a token should be put back onto the stack it may
;; also be putting a `nil' onto the stack in the first call to the
;; function.
(defmacro peg-noweb-with-file (file &rest body)
  "Execute BODY in a buffer containing the contents of FILE.

The result is nil when FILE is nil, parsing is unsuccessful, or if
`peg-noweb-filter-directory' has a computed default value of nil.

This function evaluates BODY after running the \"noweb\" root rule using
the `noweb-markup' ruleset `with-peg-rules', which is the grammar for a
noweb file marked up for noweb filters. When BODY is evaluated `filesym'
will be a symbol pointing to FILE and `parse-tree' will be the result of
parsing."
  (declare (indent 1) (debug t))
  (when peg-noweb-filter-directory
    (let ((filesym (make-symbol "file"))
          (parse-tree `(let ((,filesym ,file))
                         (when ,filesym
	                         (with-temp-buffer
	                           (insert-file-contents ,filesym)
                             (call-process (expand-file-name "markup" peg-noweb-filter-directory))
	                           (emacs-lisp-mode)
	                           ,@body
                             (goto-char (point-min))
                             ;; Switching major modes is too drastic, so just switch
                             ;; temporarily to the Emacs Lisp mode syntax table.
                             (with-syntax-table emacs-lisp-mode-syntax-table
                               (with-peg-rules '(noweb-markup)
                                 (let (peg-noweb--parser-within-codep
                                       (peg-noweb--first-stringy-token? t))
                                   (peg-run (peg noweb) #'peg-noweb--parse-failure)))))))))
      (when peg-noweb--parse-success
        ,@body))))

(defun peg-noweb--parse-failure (lst)
  "This lambda was historically named `w--parse-failure-function'."
  (setq peg-noweb--parse-success nil)
  (pop-to-buffer (clone-buffer))
  (save-excursion
    (put-text-property (point) (point-min)
                       'face 'success)

    (put-text-property (point) (point-max)
                       'face 'error)

    (goto-char (point-max))
    (message "PEXes which failed:\n%S" lst)))

(defvar peg-noweb--parse-success t; a global variable
  "The success or failure of the last parsing of noweb tool syntax.")

@

\section{A grammar of the Noweb tool markup}
\label{sec:markup-grammar}

The grammar of Noweb's tool syntax can be sectioned into five pieces, each
piece covering some aspect of parsing.

<<PEG rules>>=
<<high-level Noweb tool syntax structure>>
<<files and their paths>>
<<chunks and their boundaries>>
<<quotations>>
<<keyword definitions>>
<<meta rules>>
@

The [[noweb]] rule is the root expression which will match an instance of the
Noweb tool syntax. Erroneous or incomplete texts will not match.

As stated, the [[noweb]] rule defines the root expression---or starting
expression---for the grammar. The tool syntax of Noweb is a list
of one or more files, which are each composed of at least one chunk.
Ergo, the following [[<<high-level Noweb tool syntax structure>>]] is
defined.

<<high-level Noweb tool syntax structure>>=
;;; Overall marked-up Noweb structure without header and trailer
(define-peg-rule noweb ()
  (bob) (not header) (+ file) (not trailer) (eob))
@

It is, more or less, an error for noweb filters if the header or trailer keywords
appear in the text being parsed. These filters are irrelevant to any earlier
filter, and only matter for the final back-ends (\TeX{}, \LaTeX{}, or HTML) that
produce human-readable documenation. Normally a filter should ignore anything
that it doesn't manipulate, but here I decided to fail-safe and make it an
error. The grammar is designed with the [[--delay]] option in mind.

The grammar needs to address the fact that the syntax of the Noweb tool
format is highly line-oriented, given the influence of AWK on the design
and usage of Noweb (a historical version was entirely implemented in
AWK). The following [[<<meta rules>>]] define rules which organize the
constructs of a line-oriented, or data-oriented, syntax.

<<meta rules>>=
;; Helpers
(define-peg-rule nl ()
  (eol) "\n")
(define-peg-rule !eol ()
  (+ (not "\n") (any)))
(define-peg-rule spc ()
  " ")
@

With the [[<<meta rules>>]] enabling easier definitions of what a given
``keyword'' looks like, the /concept of a file/ can be defined. A file
is ``anything that looks like a file to Noweb'';
%% TODO: verify the functionality of:
%% -Rone.el -Rtwo.el -Rthree.el#, or that of
%% -Rone.el,two.el,three.el,four,five.h,six.c#
files may be tangled from the noweb sources by specifying their root
chunk names on the command-line. However, by default, only the chunk
named ``*'' (it's chunk header is [[@<<*>>]]) is tangled when no
specific root chunk is given on the command line.

TODO: Write about the need for the overall document to be separate from
the one-or-more files specified in the document. Exempli gratia: the
current document, contained in \whysenw{} contains two files,
though they are separately tangled: \whyseel{} and
\texttt{test-parser-with-temporary-buffer.el}. If these two files were
tangled at the same time, such that the output file discovery ability of
Noweb was used, then there would be more than one file in the
intermediate tool syntax, but still a single preceeding documentation
chunk before the first file, and a single succeeding documentation chunk
after the last file.

<<files and their paths>>=
;; Technically, file is a tagging keyword, but that classification only
;; makes sense in the Hacker's Guide to Noweb, not in the parser for the
;; tool syntax.
(define-peg-rule file ()
  (bol) "@file" spc (substring path) nl
  (action (setq w--file-current-line 0))
  (list (and (+ chunk)
             (list (or (and x-chunks i-identifiers)
                       (and i-identifiers x-chunks))))
        ;; Trailing documentation chunk and new-lines after the xref
        ;; and index.
        (opt chunk)
        (opt (+ nl)))
  `(path chunk-list -- (cons path chunk-list)))
(define-peg-rule path ()
  (opt (or ".." ".")) (* path-component) file-name)
(define-peg-rule path-component ()
  (and path-separator (+ [word])))
;; Perhaps I should instead `regexp-quote' the result of
;; `f-path-separator' rather than hard-code the UNIX-like path
;; separator. Doesn't Windows support automatic translation of UNIX-like
;; paths to Windows-paths on the current drive now?
(define-peg-rule path-separator ()
  ["\\/"])
(define-peg-rule file-name ()
  (+ (or [word] ".")))
@

NOTE: Writing PEXes for matching file names was the most difficult part
I have encountered so far, as it has forced me to understand that a
first reading of documentation is usually not sufficient to understand a
complex library in an area of programming I have not practiced in before
(language parsing).

Because chunks must not overlap, but can nest, the beginnings of chunks
need to be pushed to the parsing stack and the end of a chunk needs to
be popped off of it. The stack pushing operations in [[kind]] and
[[ordinal]] delimit chunks by their kinds and number, and the stack
actions in the [[end]] rule check that the chunk-related tokens on the
stack are balanced.

<<chunks and their boundaries>>=
(define-peg-rule chunk ()
  begin (list (* chunk-contents)) end)
(define-peg-rule begin ()
  (bol) "@begin" spc kind spc ordinal (eol) nl
  (action (if (string= (cl-second peg--stack) "code")
              (setq peg-noweb--parser-within-codep t))))
(define-peg-rule end ()
  (bol) "@end" spc kind spc ordinal (eol) nl
  (action
   (setq peg-noweb--parser-within-codep nil))
  ;; The stack grows down and the heap grows up,
  ;; that's the yin and yang of the computer thang
  `(kind-one
    ordinal-one
    keywords
    kind-two
    ordinal-two
    --
    (if (and (= ordinal-one ordinal-two) (string= kind-one kind-two))
        (cons (cons (if (string= kind-one "code")
                        'code
                      'docs)
                    ordinal-one)
              keywords)
      (error "Chunk nesting error encountered."))))
(define-peg-rule ordinal ()
  (substring [0-9] (* [0-9]))
  `(number -- (string-to-number number)))
(define-peg-rule kind ()
  (substring (or "code" "docs")))
@

Valid [[chunk-contents]] is somewhat confusing, because chunks
can contain many types of information other than text and new
lines. The definition of what is valid follows.

\begin{enumerate}
\item \texttt{text}
\item \texttt{nl}
\item \texttt{defn \textit{name}}
\item \texttt{use \textit{name}}
\item \texttt{line \textit{n}}
\item \texttt{language \textit{language}}
\item \texttt{index \ldots}
\item \texttt{xref \ldots}
\end{enumerate}

Any other keywords are invalid inside a code block. An example of an
invalid keyword is anything related to quotations! \textit{This
restriction only applies to code blocks, however, and documentation
chunks may contain quotations, of course.} As an exception, the
keywords were originally banned inside code chunks, but to parse the
noweb document in which \whyse{} itself was written it needed to be
adjusted. The grammar should be studied again to ensure that textual
description and reality are in step.

%% TODO: rephrase this and ensure it is accurate. The rules for parsing
%% were modified quite significantly from the initial definition so that it
%% would ``work'', and so that \textit{whyse.nw} would be successfully
%% parsed. ``Further, the implementation was modified to accommodate the
%% parsing of the Noweb \whysenw{} firstly.''

<<chunks and their boundaries>>=
(define-peg-rule chunk-contents ()
  (or
   <<structural keywords>>
   <<tagging keywords>>
   x-notused
   <<tool errors>>))
@

It is easier to handle the fatal keyword appearing inside chunks when it
is a permissible keyword to appear inside a chunk; this allows the
parser to consider a chunk with fatal inside of it \textit{as a valid
chunk}, but that does not mean that a chunk with a fatal keyword
inside it does not invalidate a Noweb, it still does: the fatal keyword
causes a fatal crash in parsing regardless. Those structural keywords
which may be used inside the contents of a chunk are given next.

<<structural keywords (except quotations)>>=
;; structural
text
nwnl ;; Noweb's @nl keyword, as differentiated from the rule nl := "\n".
defn
;;; NOTE: previously, a note on the following line incorrectly stated
;;; the `use' token was related to the `identifierusedinmodule' table,
;;; when it is actually related to the `parentchild' table.
use
@

All structural keywords, then, are:

<<structural keywords>>=
<<structural keywords (except quotations)>>
quotation
@

<<tagging keywords>>=
;; tagging
line
language
;; index
i-define-or-use
i-definitions
;; xref
x-prev-or-next-def
x-continued-definitions-of-the-current-chunk
i-usages
x-usages
x-label
x-ref
@

Sometimes, however, the system will permit a chunk to be undefined and
this leads to the only cases in the tool syntax where it is not
line-oriented. [[noidx]] will read the cross references to other chunks
and will be unable to generate the label, so it will insert [[@notdef]]
where it would otherwise upcase ``nw'' and then insert the label. This
is why [[x-undefined]] is placed among the other [[<<tool errors>>]]
keywords.

<<tool errors>>=
;; error
fatal
x-undefined
@

The fundamental keywords are ``text'' and ``nwnl'' (new line, per Noweb
convention). Text keywords contain source text, and any new line tokens
in the source text are replaced with the appropriate number of @nl
keywords (per convention); these are reduced to a single text token when
they are adjacent on the [[peg--stack]].

<<chunks and their boundaries>>=
(define-peg-rule text ()
  (bol) "@text" spc (substring (* (and (not "\n") (any)))) nl
  `(txt -- (peg-noweb-concatenate-text-tokens (cons 'text txt))))
(define-peg-rule nwnl ()
  (bol) (substring "@nl") nl (action (setf w--file-current-line
                                           (1+ w--file-current-line)))
  ;; Be sure that when thinking about the symbol `nl' here that
  ;; you're not confusing it with the peg rule nl.
  `(nl -- (peg-noweb-concatenate-text-tokens (cons 'nl "\n"))))
@

Nowebs are built from chunks, so the definition and usage of (i.e.
references to) a chunk are important keywords.

<<chunks and their boundaries>>=
(define-peg-rule defn ()
  "@defn" spc (substring !eol) nl
  `(name -- (cons 'chunk name)))

;; In @<<whyse.el>>=, it leads to usages tokens like below:
;; (chunk-child-usage . "Commentary")
;; (chunk-child-usage . "Code")
(define-peg-rule use ()
  (bol) "@use" spc (substring !eol) nl
  `(name --
         (if name (cons 'chunk-child-usage name)
           (error "UH-OH! There's a syntax error in the tool output!"))))
@

\begin{quotation}
Documentation may contain text and newlines, represented by @text and
[@nwnl]. It may also contain quoted code bracketed by @quote . . .
@endquote. Every @quote must be terminated by an @endquote within the
same chunk. Quoted code corresponds to the [[â¦]] construct in
the noweb source.
\end{quotation}

<<quotations>>=
(define-peg-rule quotation ()
  (bol) "@quote" nl
  (action (when peg-noweb--parser-within-codep
            (error "The parser found a quotation within a code chunk. A @fatal should have been found here, but was not.")))
  (substring (+ (and (not "@endquote") (any))))
  (bol) "@endquote" nl
  `(lst -- (cons 'quotation lst)))
@

<<keyword definitions>>=
(define-peg-rule line ()
  (bol) "@line" spc (substring ordinal) nl
  `(o -- (cons 'line o)))

(define-peg-rule language ()
  (bol) "@language" spc (substring words-eol))
@

The indexing and cross-referencing abilities of Noweb are excellent
features which enable a reader to navigate through a printed (off-line)
or on-line version of the literate document quite nicely. These
functionalities each begin with a rule which matches only part of a line
of the tool syntax since there are many indexing and cross-referencing
keywords. The common part of each line is a rule which merely matches
the [[@index]] or [[@xref]] keyword. The rest of the lines are handled
by a list of rules in [[index-keyword]] or [[xref-keyword]].


The \textit{Noweb Hacker's Guide} lists these two lines in the ``Tagging
keywords'' table, indicating that it's unlikely (or forbidden) that the
index or xref keywords would appear alone without any subsequent
information on the same line.

\begin{quotation}
@index ... Index information.

@xref ... Cross-reference information
\end{quotation}

There are many keywords defined by the Noweb tool syntax, so they
are referenced in this block and defined and documented
separately. Some of these keywords are delimiters, so they are
not given full ``keyword'' status (defined as a PEX rule) but
exist as constants in the definition of a rule that defines the
grouping.

<<keyword definitions>>=
;; Index
<<indexing and cross-referencing set-off words>>
<<fundamental indexing keywords, which are restricted to within a code chunk>>
<<the index of identifiers>>
<<unsupported indexing keywords>>

;; Cross-reference
<<cross-referencing keywords>>

;; Error
<<error-causing keywords>>
@

Further keywords are categorized neatly as Indexing or
Cross--referencing keywords, so they are contained in subsections.

\subsection{indexing}
Indexing keywords, both those used within chunks and those used outside
of chunks, are defined in this section. The
[[<<fundamental indexing keywords, which are restricted to within a code chunk>>]],
index definitions or usages of identifiers and track the definitions of
identifiers in a chunk and the usages of identifiers in a chunk. They
may seem redundant, but are not; the Noweb Hacker's Guide offers a
better explanation of the differences.

<<indexing and cross-referencing set-off words>>=
(define-peg-rule idx ()
  (bol) "@index" spc)
(define-peg-rule xr ()
  (bol) "@xref" spc)

<<fundamental indexing keywords, which are restricted to within a code chunk>>=
(define-peg-rule i-define-or-use ()
  idx
  (substring (or "defn" "use")) spc (substring !eol) nl
  (action
   (unless peg-noweb--parser-within-codep
     (error "WHYSE parse error: index definition or index usage occurred outside of a code chunk.")))
  `(s1 s2 -- (cons (make-symbol s1) s2)))

<<identifiers defined in a chunk>>
<<identifiers used in a chunk>>

<<identifiers defined in a chunk>>=
(define-peg-rule i-definitions ()
  idx "begindefs" nl
  (list (+ (and (+ i-isused) i-defitem)))
  idx "enddefs" nl
  `(definitions -- (cons 'definitions definitions)))
(define-peg-rule i-isused ()
  idx (substring "isused") spc (substring label) nl
  `(u l -- (cons 'used! l)))
(define-peg-rule i-defitem ()
  idx (substring "defitem") spc (substring !eol) nl
  `(d i -- (cons 'def-item i)))

<<identifiers used in a chunk>>=
(define-peg-rule i-usages ()
  idx "beginuses" nl
  (list (+ (and (+ i-isdefined) i-useitem)))
  idx "enduses" nl
  `(usages -- (cons 'usages usages)))
(define-peg-rule i-isdefined ()
  idx (substring "isdefined" spc label) nl)
(define-peg-rule i-useitem ()
  idx (substring "useitem" spc !eol) nl) ;; !eol :== ident
@

The summary index of identifiers is a file--specific set of keywords.
The index lists all identifiers defined in the file (at least all of
those recognized by the autodefinitions filter).

<<the index of identifiers>>=
(define-peg-rule i-identifiers ()
  idx "beginindex" nl
  (list (+ i-entry))
  idx "endindex" nl
  `(l -- (cons 'i-identifiers l)))
(define-peg-rule i-entry ()
  idx "entrybegin" spc (substring label spc !eol) nl
  (list (+ (or i-entrydefn i-entryuse)))
  idx "entryend" nl
  `(entry-label lst -- (cons 'entry-label lst)))
(define-peg-rule i-entrydefn ()
  idx (substring "entrydefn") spc (substring label) nl
  `(defn label -- (cons 'defn label)))
(define-peg-rule i-entryuse ()
  idx (substring "entryuse") spc (substring label) nl
  `(use lst -- (cons 'use lst)))
@

The following chunk's name is documentation enough for the purposes of
\whyse{}. See the Noweb Hacker's Guide for more information.

[[@index nl]] was deprecated in Noweb 2.10, and [[@index localdefn]] is
not widely used (assumedly) nor well-documented, so it is unsupported by
\whyse{} (contributions for improved support are welcomed).

<<unsupported indexing keywords>>=
;; @index nl was deprecated in Noweb 2.10, and @index localdefn is not
;; widely used (assumedly) nor well-documented, so it is unsupported by
;; WHYSE (contributions for improved support are welcomed).
(define-peg-rule i-localdefn ()
  idx "localdefn" spc !eol nl)
(define-peg-rule i-nl ()
  idx "nl" spc !eol nl
  (action (error <<index nl error message>>)))
@

\subsection{cross referencing}
<<cross-referencing keywords>>=
(define-peg-rule x-label ()
  xr (substring "label" spc label) nl
  `(substr -- (cons 'x-label (cadr (split-string substr)))))
(define-peg-rule x-ref ()
  xr (substring "ref" spc label) nl
  `(substr --  (cons 'ref (cadr (split-string substr)))))

;; FIXME: improve the error handling at this point. It is not fragile
;; any longer, because most things are ignored and this is hackish;
;; however, the message reporting is not too helpful. It would be nice
;; to have _only_ the chunk name reported, and formatted with @<< and >>.
;;
;; TODO: Reproduction steps: make a reference to an undefined code chunk
;; within another code chunk. For fixing this issue, undefined code
;; chunks should also be referenced within quotations in documentation.
(define-peg-rule x-undefined ()
  xr (or "ref" "chunkbegin") spc
  (guard
   (if (string= "nw@notdef"
                (buffer-substring-no-properties (point) (+ 9 (point))))
       (error (format "%s: %s: %s:\n@<@<%s>>"
                      "WHYSE"
                      "nw@notdef detected"
                      "an undefined chunk was referenced"
                      (buffer-substring-no-properties (progn (forward-line) (point))
                                                      (end-of-line)))))))

(define-peg-rule x-prev-or-next-def ()
  xr (substring (or "nextdef" "prevdef")) spc (substring label) nl
  `(previous-or-next-chunk-defn label -- (cons (make-symbol previous-or-next-chunk-defn) label)))

(define-peg-rule x-continued-definitions-of-the-current-chunk ()
  xr "begindefs" nl
  (list (+ (and xr (substring "defitem") spc (substring label) nl)))
  xr "enddefs" nl)

(define-peg-rule x-usages ()
  xr "beginuses" nl
  (list (+ (and xr "useitem" spc (substring label) nl)))
  xr "enduses" nl)

(define-peg-rule x-notused ()
  xr "notused" spc (substring !eol) nl
  `(name -- (cons 'unused! name)))
(define-peg-rule x-chunks ()
  nwnl
  nwnl
  xr "beginchunks" nl
  (list (+ x-chunk))
  xr "endchunks" nl
  `(l -- (cons 'x-chunks l)))
(define-peg-rule x-chunk ()
  xr "chunkbegin" spc (substring label) spc (substring !eol) nl
  (list (+ (list (and xr
                      (substring (or "chunkuse" "chunkdefn"))
                      `(chunk-usage-or-definition -- (make-symbol chunk-usage-or-definition))
                      spc
                      (substring label)
                      nl))))
  xr "chunkend" nl)

;; Associates label with tag (@xref tag $LABEL $TAG)
(define-peg-rule x-tag ()
  xr "tag" spc label spc !eol nl)
(define-peg-rule label ()
  (+ (or "-" [alnum]))) ;; A label never contains whitespace.

<<error-causing keywords>>=
;; User-errors (header and trailer) and tool-error (fatal)
;; Header and trailer's further text is irrelevant for parsing, because they cause errors.
(define-peg-rule header ()
  (bol) "@header" ;; formatter options
  (action (error "[ERROR] Do not use totex or tohtml in your noweave pipeline.")))
(define-peg-rule trailer ()
  (bol) "@trailer" ;; formatter
  (action (error "[ERROR] Do not use totex or tohtml in your noweave pipeline.")))
(define-peg-rule fatal ()
  (bol) "@fatal"
  (action (error "[FATAL] There was a fatal error in the pipeline. Stash the work area and submit a bug report against Noweb, WHYSE, and other relevant tools.")))
@

<<index nl error message>>=
(string-join
 '("\"@index nl\" detected."
   "This indicates hand-written @ %def syntax in the Noweb source."
   "This syntax was deprecated in Noweb 2.10, and is entirely unsupported."
   "Write an autodefs AWK script for the language you are using.")
 "\n")
@

\section{Parse Tree Processing}
\label{sec:parse-tree-processing}

The parse tree is a list of noweb documents, each being a list
themselves. The first atom of an inner list, corresonding to a document,
is the filename of that document (hopefully the same filename as passed
on the commmand-line elsewhere when the document is used).

Deeper, each document-list contains as the second atom a list of its
contents, which is an association list thereof. Each association in the
alist is bewteen the symbol relating to the rule that generated the cons
cell, and the contents appropriate to the symbol.

The first
step is to ensure the association lists in the parse tree are in a
format that is acceptable to built-in Emacs Lisp functions; this will
make it easier to navigate the tree and transform it.
%% FIXME: is it really true, and does it make sense for
%% what I'm actually doing, or am I using the concept/name wrong?
Other texts call this manipulation of the parse tree ``list
destructuring''.

%% FIXME 2024-08-10 what the fuck am I saying here?
Some associations are reductions from the initial parse tree,
which---thanks to the \textsc{peg} package and \textit{PEG parsing in
  general}---are not reduced in a second step. Modifications to the
parsing procedure can occur directly without losing information, and
thanks to literate programming should be easy for advanced users.

The initial parse tree begins like the one below.

\begin{verbatim}
'((noweb-document-one
   ((docs . 0)
    (text . "\tex{} is cool!"))
   ((code . 1)
    (text . "(message \"LISP is awesome!\")")))
  (noweb-document-two
   ((code . 0)
    (text . "asdf is a system definition format in Common LISP,"))
   (nwnl . "\n")
   (text . "and I like to use it.")
   ((code . 1)
    (text . "jkl; is the right-handed corollary of asdf."))
   ((docs . 2)
    (text . "\LaTeX{} is great!"))
   ((docs . 3)
    (text . "Noweb, written by Norman Ramsey is sweet!"))))
\end{verbatim}

The reductions which occur during parsing make chunk zero of the second
noweb document look like this in the final result.

\begin{verbatim}
((code . 0)
 (text . "asdf is a system definition format in Common LISP,
and I like to use it."))
\end{verbatim}

The new result is much easier to use as data for other programs (SQL in
this case). In the verbatim text a literal newline was inserted rather
than retaining the escape sequence, which is exactly what happens in the
reduction step as well. The next subsection discusses the details of how
the reduction in complexity exampled above is achieved.

\subsection{Reducing complexity in the alist}
The first step in making the parse tree navigable for other programs is
collapsing adjacent ``stringy'' tokens into single [[text]] tokens. The
output tool syntax of notangle, and the parse tree resulting from the
PEG, (breifly) contain individual text tokens for fragments of whole
text lines and form feed characters. These tokens exist because the
cross-referencing tokens fragment the text lines, and new lines in the
noweb document are treated specially to facilitate this fragmentation.

A small quote from the tool syntax of a development version of \whyse{} is
shown in this example in its parsed form. However, during actual parsing
these adjacent tokens are \textit{immediately collapsed} into singular
tokens.

\begin{verbatim}
(text . "  and \textsc{Noweb}'s \texttt{finduses.nw}!")
(nwnl . "@nl")
(text . "\end{enumerate}")
(nwnl . "@nl")
(text . "")
(nwnl . "@nl")
\end{verbatim}

To collapse these tokens into a single text token the [[peg--stack]]
must be manipulated carefully. It isn't advisable to manipulate this
variable in the course of a PEG grammar's actions. There is a use case
for it when the previous rules and actions won't accommodate the
necessary action without refactoring a larger part of the grammar. In
this development version that is not a goal; basic functionality is
sought after, not robustness or beauty, so hacking the desired behaviour
together quickly is better.

[[peg-noweb-nth-chunk-of-nth-noweb-document]] retrieves the parse tree for the nth
noweb document, which in the case of [[whyse.nw]] is the parse tree of
the zeroth-indexed document. It's quite a simple function. To obtain a
given chunk of this document from the parse tree the result of the
function is called with [[nth]] and the index of the chunk.

<<code>>=
<<functions for navigating noweb tool syntax parse trees>>

<<functions for navigating noweb tool syntax parse trees>>=
(defun peg-noweb-nth-document-file-name (nth-document parse-tree)
  "Return the file name of the nth-indexed document in the parse tree.

For the first document in the parse tree, that is the
zeroth-indexed document."
  (cl-first (nth nth-document parse-tree)))

(defun peg-noweb-nth-document (nth-document parse-tree)
  "Return the subtree of the nth-indexed document in the parse tree."
  (cl-second (nth nth-document parse-tree)))

(defun peg-noweb-nth-chunk-of-document (n document)
  "Return the subtree for the Nth chunk of a noweb document parse subtree."
  (nth n document))

(defun peg-noweb-chunk-number (chunk)
  "Return the chunk number of CHUNK."
  (or (cdr (assq 'code chunk))
      (cdr (assq 'docs chunk))))

(defun peg-noweb-nth-chunk-of-nth-noweb-document (nth-chunk nth-document parse-tree)
  (peg-noweb-nth-chunk-of-document nth-chunk (peg-noweb-nth-document nth-document parse-tree)))

(defun peg-noweb-chunk-text (chunk)
  "Join all the strings returned from the collection in the loop,
and return the single string."
  (string-join
   (cl-loop for elt in chunk collect
            (when (and (listp elt) (equal 'text (car elt)))
              (cdr elt)))
   ""))

(defun peg-noweb-chunk-name (chunk)
  "Return non-nil if CHUNK is a code chunk, and thereby has a name.

The return value, if non-nil, is actually the name of the chunk."
  (if-let ((name (assq 'chunk chunk)))
      (cdr name)))

(defun peg-noweb-concatenate-text-tokens (new-token)
  "Join the values of two text token associations in a two-element token alist.

If the two associations shouldn't be joined, return them to the stack."
  (prog1
      ;; Concatenation only occurs when the previous token examined was
      ;; a text or nwnl token, ergo there must have been a text or nwnl
      ;; token previously examined for any concatenation to occur. When
      ;; no such token has been examined immediately return the
      ;; (stringy) token recieved and indicate it must have been a
      ;; stringy token by chaning the value of `peg-noweb--first-stringy-token?'
      ;; accordingly. Subsequent runs will then operate on potential
      ;; pairs of stringy tokens.
      (if-let ((not-first-stringy-token? (not peg-noweb--first-stringy-token?))
               (previous-token  (pop peg--stack))
               ;; The previous token cannot be a text or nwnl token if
               ;; it is not a list, and checking prevents causing an
               ;; error by taking the `car' of a non-list token, e.g. the
               ;; filename token.
               (previous-token-is-alist?
                (prog1 (and (listp previous-token)
                            (listp new-token)
                            (or (assoc 'text `(,new-token))
                                (assoc 'nl `(,new-token)))
                            (or (assoc 'text `(,previous-token))
                                (assoc 'nl `(,previous-token)))))))
          ;; Join the association's values and let the caller push a single
          ;; token back onto the `peg--stack'.
          (cons 'text (format "%s%s" (cdr previous-token)
                              (cdr new-token)))

        ;; Push the previous token back to the `peg--stack', and let the
        ;; caller push the new token to that stack.
        (push previous-token peg--stack)
        new-token)
    (when peg-noweb--first-stringy-token? (setq peg-noweb--first-stringy-token? nil))))
@

\end{document}


% Local Variables:
% mode: poly-noweb
% poly-noweb-innermode: emacs-lisp-mode
% noweb-code-mode: emacs-lisp-mode
% End:
