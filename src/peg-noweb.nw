\documentclass{article}

\usepackage{hyperref}
\usepackage{quoting,xparse}
\usepackage{biblatex}
\usepackage{noweb}

\newcommand{\whyse}{\textsc{WHYSE}}

%% NOTE: the following new document commmand and environment were provided by
%% StackExchange user egreg (https://tex.stackexchange.com/a/391739); the code
%% is subject to the "Attribution-ShareAlike 3.0 Unported" license
%% (https://creativecommons.org/licenses/by-sa/3.0/), which is published by
%% Creative Commons.
\NewDocumentCommand{\bywhom}{m}{% the Bourbaki trick
  {\nobreak\hfill\penalty50\hskip1em\null\nobreak
   \hfill\mbox{\normalfont(#1)}%
   \parfillskip=0pt \finalhyphendemerits=0 \par}%
}
\NewDocumentEnvironment{pquotation}{m}
  {\begin{quoting}[
     indentfirst=true,
     leftmargin=\parindent,
     rightmargin=\parindent]\itshape}
  {\bywhom{#1}\end{quoting}}

\begin{document}

\begin{abstract}
  The \textsc{peg} package for \textsc{Emacs} provides automatic parser
  generation from a formal grammar. The grammar for noweb released in this
  package is based off of the description of \emph{the tool syntax} given in the
  \cite[Noweb Hacker's Guide]{ramsey1992}.

  The formal grammar for Norman Ramsey's popular Noweb was completed during the
  early development of \whyse{}, a package separate from this one. Having a
  complete formal grammar, the resulting parse tree from the automatically
  generated parser was nearly complete: only traversal and manipulation of that
  tree were insufficiently developed. Writing a useful pulic interface to the
  parse tree before continuing on any other adventure in WHYSE-land may help me
  complete this subproject, at least.
\end{abstract}

\section{The \textit{PEG Noweb} Emacs Package}
\label{sec:pkg-meta}

<<peg-noweb.el>>=
;;; peg-noweb.el --- PEG ruleset for the Noweb Tool Syntax -*- lexical-binding: t -*-

;; Copyright Â© 2025 Bryce Carson

;; Author: Bryce Carson <bryce.a.carson@gmail.com>
;; Version: 0.1
;; Package-Requires: ((peg "1.0.1"))
;; Keywords: tools, tex, hypermedia, peg
;; URL: https://github.com/bryce-carson/peg-noweb

;; This file is not part of GNU Emacs.

<<Licensing and copyright>>

;;; Commentary:
;; This file defines a PEG ruleset for Noweb's tool syntax, which is normally
;; used to extend Noweb with UNIX tools like AWK or sed. Parsing the tool syntax
;; allows it to be manipulated as LISP data, and potentially used as LISP code
;; depending on the user-provided extensions.
;;
;; The main purpose of this package is to separate the concern of maintaining
;; the grammar for the tool syntax and the maintenance of WHYSE, which was
;; originally designed with PEG parsing at its core.

;;; Code:
<<PEG rules and the Noweb ruleset>>
<<define customization variables>>
<<define functions>>
<<define variables>>

(provide 'peg-noweb)

;; Local Variables:
;; mode: emacs-lisp
;; no-byte-compile: t
;; no-native-compile: t
;; End:

;;; peg-noweb.el ends here
@

\subsection{Licensing and Copyright}
\label{sec:pkg-license}

This subsection contains licensing and copyright information for PEG Noweb, and
any relevant third-party copyright notices.

<<Licensing and copyright>>=
;; This program is free software: you can redistribute it and/or
;; modify it under the terms of the GNU General Public License as
;; published by the Free Software Foundation, either version 3 of the
;; License, or (at your option) any later version.

;; This program is distributed in the hope that it will be useful, but
;; WITHOUT ANY WARRANTY; without even the implied warranty of
;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
;; General Public License for more details.

;; You should have received a copy of the GNU General Public License
;; along with this program. If not, see
;; <https://www.gnu.org/licenses/>.
@

\section{Public Interface}
\label{sec:pkg-interface}

This section defines a public interface to the grammar, allowing texts matched
by the grammar to be navigated and searched using simple functions and
manipulated in manners common to the texts matched by the grammar.

The public interface of the package should include some basic Emacs LISP
programming facilities, otherwise it would be difficult to program any
application with only the interface to the ruleset; users shouldn't need to be
familiar with the peg package itself or parsing to utilize this interface. There
should some input and output functionality at least: a text in a buffer must be
supplied to the function \texttt{with-peg-rules}.

<<example-0>>=
(with-peg-rules (peg-noweb-ruleset)
  BODY)
@ 

Whatever happens in BODY that I like to do during development of WHYSE using
peg-noweb is likely something that should be packaged into peg-noweb.

\subsection{Customization}
\label{sec:customization}

To utilize \textit{markup}, the customization variable
\texttt{peg-noweb-filter-directory} must be set, otherwise the default value
will come from parsing the standard error of \texttt{noweave -v}, a cental
command distributed in Noweb which must be on the user's PATH.

<<define customization variables>>=
(defgroup peg-noweb ()
  "Customization Variables affecting PEG Noweb, the peg package extension library providing a ruleset for the Noweb tool syntax.")

(defcustom peg-noweb-filter-directory
  (and (= 0 (shell-command "which noweave"))
       (with-temp-buffer (shell-command "noweave -v -n" (get-buffer (current-buffer)))
                         (file-name-directory (buffer-substring (goto-line 3) (- (point-at-eol) 2)))))
  "The directory containing Noweb filters, which also contains the executable `markup' in particular."
  :group 'peg-noweb)
@

It's immediately useful to have a function to markup noweb files to produce the
all-important tool format.

<<define functions>>=
(defun peg-noweb-filter-markup (infile &optional outfile)
  "Filter INFILE through markup to create OUTFILE, returning OUTFILEs path.

By default, OUTFILE has the same name as INFILE with the `mu' extenion instead of `nw'."
  (let ((outfile (if outfile outfile
                   (concat (file-name-sans-extension infile) ".mu"))))
    (call-process (file-name-concat peg-noweb-filter-directory "markup")
                  nil `(:file ,outfile) nil infile)
    outfile))
@

Noweb's key programs take multiple files as arguments, so the functions I define
which call these programs should likewise support multiple arguments. Therefore
\texttt{peg-noweb-filter-markup} will be redefined in-place, leaving this
function unused.

\subsection{Variables}
\label{sec:variables}

During testing, with the Makefile target ``test-interactive'', I found that the
PEG parser wasn't happy with the following variables being undefined, despite
each having exclusively local values during parsing.

<<define variables>>=
(defvar peg-noweb--file-number-record 0
  "The current line of the current file being processed by peg-noweb.
`peg-noweb--file-number-record' emulates \"FNR\" in the AWK programming
language.")
;; NOTE: deprecated.
(defvar peg-noweb--first-stringy-token? t
  "Is the current token the (possible) beginning of a series of \"@text\" tokens?")
(defvar peg-noweb--parser-within-code-chunk? nil
  "Whether the peg-noweb parser is currently within a code chunk.")
(defvar peg-noweb--parse-success t
  "The success or failure of the last parsing of noweb tool syntax.")
@ 

\subsection{Macros}
\label{sec:macros}

Adapted from \texttt{lm-with-file} from \texttt{lisp-mnt.el}, I provide
\texttt{peg-noweb-with-file}. The file argument is the file which will be passed
to \texttt{nomarkup}, and the output is captured by Emacs.

<<define functions>>=
(defun peg-noweb--parse-failure (lst)
  (setq peg-noweb--parse-success nil)
  (pop-to-buffer (clone-buffer))
  (save-excursion
    (put-text-property (point) (point-min)
                       'face 'success)

    (put-text-property (point) (point-max)
                       'face 'error)

    (goto-char (point-max))
    (message "PEXes which failed:\n%S" lst)))

(defun peg-noweb-parse-buffer (buffer)
  "Parse the buffer, with BUFFER current."
  (interactive "bbuffer:")
  (with-current-buffer buffer
    (goto-char (point-min))
    (peg-noweb-parse-at-point)))

(defun peg-noweb-parse-at-point ()
  "Parse the current buffer beginning at point."
  (with-peg-rules (peg-noweb-ruleset)
    (let (peg-noweb--parser-within-code-chunk?; nil
          (peg-noweb--first-stringy-token? t))
      (peg-run (peg noweb) #'peg-noweb--parse-failure))))

(defun peg-noweb-parse-files (&rest files)
  "Parse the Noweb files in FILES, calling `markup' on the files."
  (let ((files (mapcar #'expand-file-name files)))
    (with-temp-buffer
      (unless (listp files)
        (error "FILES is not a list!"))
      (eval `(call-process (expand-file-name "markup" peg-noweb-filter-directory)
                           nil t nil ,@files))
      (peg-noweb-parse-buffer (current-buffer)))))
@

\section{A grammar of the Noweb tool markup}
\label{sec:markup-grammar}

\begin{quotation}% I`m quoting myself, so I don't need any attribution. This is
                 % just old text I haven't gotten rid of yet.
  Every character of an input text to be parsed by \textit{parsing expressions} in a PEG
  must be defined in terminal rules of the formal grammar.
  %% NOTE: to match the new line character in a text stream, the string literal
  %% "\n" must be included. The (eol) PEG rule /tests/ for the end of line by
  %% guarding against unintended evaluation of the boolean return value of the
  %% standard Emacs Lisp (eolp). To test if point is at the end of a line, use
  %% (eol); to match the end of line, and permit parsing the next line of input,
  %% include the string literal "\n".
  The root rule in the grammar for Noweb tool syntax is named \texttt{noweb}, so
  with \texttt{@<<PEG rules>>} in scope a match using the root rule
  \texttt{noweb} is attempted against the current buffer. The current buffer
  must contain the tool syntax produced by \texttt{noweave} and passed to any
  one of the default or additional filters specified on the command line.

  To further the development of \whyse{}, packaging \texttt{@<<PEG rules>>} as an
  independent peg package extension allows me to forget about this subproject
  while I focus on Ref\TeX{} and AUC\TeX{} as foundational layers for
  implementing \whyse{}.
\end{quotation}

The grammar of Noweb's tool syntax can be sectioned into five pieces, each
piece covering some aspect of parsing.

<<PEG rules>>=
<<high-level Noweb tool syntax structure>>
<<files and their paths>>
<<chunks and their boundaries>>
<<quotations>>
<<keyword definitions>>
<<meta rules>>
@

The \texttt{noweb} rule is the root expression which will match an instance of
the Noweb tool syntax. Erroneous or incomplete texts will not match. The root
rule is just one rule among many defined within the \texttt{noweb-markup} PEG
ruleset. A public API for the interacting with texts matched by the
\texttt{noweb} rule when using the ruleset, and texts which should match the
grammar it defines are given in other sections.

<<PEG rules and the Noweb ruleset>>=
<<PEG rules>>

(define-peg-ruleset peg-noweb-ruleset
  '(noweb

    nl
    !eol
    spc

    file
    path
    directory
    path-separator
    file-name

    chunk
    begin
    end-of-defun-function
    ordinal
    kind
    chunk-contents

    text
    nwnl

    defn
    use

    quotation

    line
    language

    idx
    xr

    i-define-or-use

    i-definitions
    i-isused
    i-defitem

    i-usages
    i-isdefined
    i-useitem

    i-identifiers
    i-entry
    i-entrydefn
    i-entryuse

    i-localdefn; NOTE: not widely used nor well-documented.
    i-nl; NOTE: deprecated in Noweb 2.10.

    x-label
    x-ref
    x-undefined
    x-prev-or-next-def

    x-continued-definitions-of-the-current-chunk
    x-usages

    x-notused
    x-chunks
    x-chunk

    x-tag
    label

    header
    trailer
    fatal))

@ 

As stated, the \texttt{noweb} rule defines the root expression---or starting
expression---for the grammar. The tool syntax of Noweb is a list of one or more
files, which are each composed of at least one chunk. Ergo, the following
\texttt{@<<high-level Noweb tool syntax structure>>} is defined.

<<high-level Noweb tool syntax structure>>=
;;; Overall marked-up Noweb structure without header and trailer
(define-peg-rule noweb ()
  (bob) (not header) (+ file) (not trailer) (eob))
@

It is an error, more or less so, for noweb filters if the header or trailer
keywords appear in the text being parsed. These filters are irrelevant to any
earlier filter, and only matter for the final back-ends (\TeX{}, \LaTeX{}, or
HTML) that produce human-readable documenation. Normally a filter should ignore
anything that it doesn't manipulate, but here I decided to fail-safe and make it
an error. The grammar is designed with the \texttt{--delay} option in mind.

The grammar needs to address the fact that the syntax of the Noweb tool
format is highly line-oriented, given the influence of AWK on the design
and usage of Noweb (a historical version was entirely implemented in
AWK). The following \texttt{@<<meta rules>>} define rules which organize the
constructs of a line-oriented, or data-oriented, syntax.

<<meta rules>>=
;; Helpers
(define-peg-rule nl ()
  "\n")
(define-peg-rule !eol ()
  (+ (not "\n") (any)))
(define-peg-rule spc ()
  " ")
@

With the \texttt{@<<meta rules>>} enabling easier definitions of what a given
``keyword'' looks like, the \textit{concept of a file} can be defined. A file is
``anything that looks like a file to Noweb'';
%% TODO: verify the functionality of:
%% -Rone.el -Rtwo.el -Rthree.el#, or that of
%% -Rone.el,two.el,three.el,four,five.h,six.c#
files may be tangled from the noweb sources by specifying their root
chunk names on the command-line. However, by default, only the chunk
named ``*''
(it's chunk header is \texttt{@<<*>>})%@<<: prohibit Noweb inserting a @use here
is tangled when no
specific root chunk is given on the command line.

TODO: Write about the need for the overall document to be separate from the
one-or-more files specified in the document. Exempli gratia: the current
document, contained in \texttt{peg-noweb.nw} contains more than one file, these
separately tangled. If these two files were tangled at the same time, such that
the output file discovery ability of Noweb was used, then there would be more
than one file in the intermediate tool syntax, but still a single preceeding
documentation chunk before the first file, and a single succeeding documentation
chunk after the last file. When woven, however, the ``overall document'' will
include all files and the surrounding text.

\begin{itemize}
\item multiple noweb files
\item multiple roots within multiple noweb files
\item single noweb files
\item multiple roots within a single noweb file
\end{itemize}

When \texttt{noweave} is given multiple noweb files there will be multiple
\texttt{@file} tags in the markup output.

TODO: a paragraph about root chunks within file(s).

<<files and their paths>>=
;; Technically, file is a tagging keyword, but that classification only
;; makes sense in the Hacker's Guide to Noweb, not in the parser for the
;; tool syntax.
(define-peg-rule file ()
  (bol) "@file" spc (substring path) (eol) "\n"; the file tagging keyword ends here
  (action (setq peg-noweb--file-number-record 0))
  (list (and (+ chunk)
             (list (opt (or (and x-chunks i-identifiers)
                            (and i-identifiers x-chunks)))))
        ;; Trailing documentation chunk and new-lines after the xref
        ;; and index.
        (opt chunk)
        (opt (+ nl)))
  `(path chunk-list -- (cons path chunk-list)))

(define-peg-rule path ()
  (* directory) (opt "/") file-name)

(define-peg-rule file-name ()
  ;; NOTE: while POSIX filenames themselves can theoretically include new-lines,
  ;; noweb syntax does not allow this.
  (+ (and (not ["\x00" "/" "\n"]) (any))))

;; A directory may include a relative specifier, or a directory specifier,
;; but will always include a slash to indicate one or more directory components.
;; `/' is the unnamed root directory, `/root-subdirectory',
;; `../root-subdirectory' would be `/', etc. NOTE: this PEX also matches the
;; final directory separator!
(define-peg-rule directory ()
  ;; Perhaps I should instead `regexp-quote' the result of
  ;; `f-path-separator' rather than hard-code the UNIX-like path
  ;; separator. Doesn't Windows support automatic translation of UNIX-like
  ;; paths to Windows-paths on the current drive now?
  (opt (or ".." "."))
  "/"
  (if (not (and file-name "\n")))
  (opt file-name))
@

NOTE: Writing PEXes for matching file names was the most difficult part
I have encountered so far, as it has forced me to understand that a
first reading of documentation is usually not sufficient to understand a
complex library in an area of programming I have not practiced in before
(language parsing).

Because chunks must not overlap, but can nest, the beginnings of chunks
need to be pushed to the parsing stack and the end of a chunk needs to
be popped off of it. The stack pushing operations in \texttt{kind} and
\texttt{ordinal} delimit chunks by their kinds and number, and the stack
actions in the \texttt{end} rule check that the chunk-related tokens on the
stack are balanced.

<<chunks and their boundaries>>=
(define-peg-rule chunk ()
  begin (list (* chunk-contents)) end)
(define-peg-rule begin ()
  (bol) "@begin" spc kind spc ordinal (eol) nl
  (action (if (string= (cl-second peg--stack) "code")
              (setq peg-noweb--parser-within-code-chunk? t))))
(define-peg-rule end ()
  (bol) "@end" spc kind spc ordinal (eol) nl
  (action
   (setq peg-noweb--parser-within-code-chunk? nil))
  ;; The stack grows down and the heap grows up,
  ;; that's the yin and yang of the computer thang
  `(kind-one
    ordinal-one
    keywords
    kind-two
    ordinal-two
    --
    (if (and (= ordinal-one ordinal-two) (string= kind-one kind-two))
        (cons (cons ordinal-one
                    (if (string= kind-one "code")
                        'code
                      'docs))
              keywords)
      (error "Chunk nesting error encountered."))))
(define-peg-rule ordinal ()
  (substring [0-9] (* [0-9]))
  `(number -- (string-to-number number)))
(define-peg-rule kind ()
  (substring (or "code" "docs")))
@

Valid \texttt{chunk-contents} is somewhat confusing, because chunks
can contain many types of information other than text and new
lines. The definition of what is valid follows.

\begin{enumerate}
\item \texttt{text}
\item \texttt{nl}
\item \texttt{defn \textit{name}}
\item \texttt{use \textit{name}}
\item \texttt{line \textit{n}}
\item \texttt{language \textit{language}}
\item \texttt{index \ldots}
\item \texttt{xref \ldots}
\end{enumerate}

Any other keywords are invalid inside a code block. An example of an
invalid keyword is anything related to quotations! \textit{This
restriction only applies to code blocks, however, and documentation
chunks may contain quotations, of course.} As an exception, the
keywords were originally banned inside code chunks, but to parse the
noweb document in which \whyse{} itself was written it needed to be
adjusted. The grammar should be studied again to ensure that textual
description and reality are in step.

%% TODO: rephrase this and ensure it is accurate. The rules for parsing
%% were modified quite significantly from the initial definition so that it
%% would ``work'', and so that \textit{whyse.nw} would be successfully
%% parsed. ``Further, the implementation was modified to accommodate the
%% parsing of the Noweb \whysenw{} firstly.''

<<chunks and their boundaries>>=
(define-peg-rule chunk-contents ()
  (or
   <<structural keywords>>
   <<tagging keywords>>
   x-notused
   <<tool errors>>))
@

It is easier to handle the fatal keyword appearing inside chunks when it
is a permissible keyword to appear inside a chunk; this allows the
parser to consider a chunk with fatal inside of it \textit{as a valid
chunk}, but that does not mean that a chunk with a fatal keyword
inside it does not invalidate a Noweb, it still does: the fatal keyword
causes a fatal crash in parsing regardless. Those structural keywords
which may be used inside the contents of a chunk are given next.

<<structural keywords (except quotations)>>=
;; structural
text
nwnl ;; Noweb's @nl keyword, as differentiated from the rule nl := "\n".
defn
;;; NOTE: previously, a note on the following line incorrectly stated
;;; the `use' token was related to the `identifierusedinmodule' table,
;;; when it is actually related to the `parentchild' table.
use
@

All structural keywords, then, are:

<<structural keywords>>=
<<structural keywords (except quotations)>>
quotation
@

<<tagging keywords>>=
;; tagging
line
language
;; index
i-nl; NOTE: recognized, but unsupported.
i-define-or-use
i-definitions
;; xref
x-prev-or-next-def
x-continued-definitions-of-the-current-chunk
i-usages
x-usages
x-label
x-ref
@

Sometimes, however, the system will permit a chunk to be undefined and
this leads to the only cases in the tool syntax where it is not
line-oriented. \texttt{noidx} will read the cross references to other chunks
and will be unable to generate the label, so it will insert \texttt{@notdef}
where it would otherwise upcase ``nw'' and then insert the label. This
is why \texttt{x-undefined} is placed among the other \texttt{@<<tool errors>>}
keywords.

<<tool errors>>=
;; error
fatal
x-undefined
@

The fundamental keywords are ``text'' and ``nwnl'' (new line, per Noweb
convention). Text keywords contain source text, and any new line tokens
in the source text are replaced with the appropriate number of @nl
keywords (per convention); these are reduced to a single text token when
they are adjacent on the \texttt{peg--stack}.

<<chunks and their boundaries>>=
(define-peg-rule text ()
  (bol) "@text" spc (substring (* (and (not "\n") (any)))) nl
  `(txt -- (cons 'text txt)))
(define-peg-rule nwnl ()
  (bol) (substring "@nl") nl
  (action (cl-incf peg-noweb--file-number-record))
  `(nl -- (cons 'nl "\n")))
@

Nowebs are built from chunks, so the definition and usage of (i.e.
references to) a chunk are important keywords.

<<chunks and their boundaries>>=
(define-peg-rule defn ()
  "@defn" spc (substring (opt !eol)) nl
  `(name -- (cons 'chunk name)))

;; In @<<whyse.el>>=, it leads to usages tokens like below:
;; (use . "Commentary")
;; (use . "Code")
(define-peg-rule use ()
  (bol) "@use" spc (substring !eol) nl
  `(name --
         (if name (cons 'use name)
           (error "UH-OH! There's a syntax error in the tool output!"))))
@

\begin{pquotation}{Norman Ramsey, 1992}
  Depending on its kind, a chunk may contain documentation or code.
  Documentation may contain text and newlines, represented by \texttt{@text} and
  \texttt{@nl}. It may also contain quoted code bracketed by
  \texttt{@quote...@endquote}. Every \texttt{@quote} must be terminated by an
  \texttt{@endquote} within the same chunk. Quoted code corresponds to the
  \texttt{[[...]]} construct in the noweb source.
\end{pquotation}

<<quotations>>=
(define-peg-rule quotation ()
  (bol) "@quote" nl
  (action (when peg-noweb--parser-within-code-chunk?
            (error "The parser found a @quote within a code chunk. A @fatal should have been substituted here by a previous tool, but was not.")))
  (substring (+ (and (not (and (bol) "@endquote")) (any))))
  (bol) "@endquote" nl
  `(lst -- (cons 'quotation lst)))
@

<<keyword definitions>>=
(define-peg-rule line ()
  (bol) "@line" spc (substring ordinal) nl
  `(o -- (cons 'line o)))

(define-peg-rule language ()
  (bol) "@language" spc (substring words-eol))
@

The indexing and cross-referencing abilities of Noweb are excellent
features which enable a reader to navigate through a printed (off-line)
or on-line version of the literate document quite nicely. These
functionalities each begin with a rule which matches only part of a line
of the tool syntax since there are many indexing and cross-referencing
keywords. The common part of each line is a rule which merely matches
the \texttt{@index} or \texttt{@xref} keyword. The rest of the lines are handled
by a list of rules in \texttt{index-keyword} or \texttt{xref-keyword}.

The \textit{Noweb Hacker's Guide} lists these two lines in the ``Tagging
keywords'' table, indicating that it's unlikely (or forbidden) that the
index or xref keywords would appear alone without any subsequent
information on the same line.

\begin{quotation}
@index ... Index information.

@xref ... Cross-reference information
\end{quotation}

There are many keywords defined by the Noweb tool syntax, so they
are referenced in this block and defined and documented
separately. Some of these keywords are delimiters, so they are
not given full ``keyword'' status (defined as a PEX rule) but
exist as constants in the definition of a rule that defines the
grouping.

<<keyword definitions>>=
;; Index
<<indexing and cross-referencing set-off words>>
<<fundamental indexing keywords, which are restricted to within a code chunk>>
<<the index of identifiers>>
<<unsupported indexing keywords>>

;; Cross-reference
<<cross-referencing keywords>>

;; Error
<<error-causing keywords>>
@

Further keywords are categorized neatly as Indexing or
Cross--referencing keywords, so they are contained in subsections.

\subsection{Indexing}
Indexing keywords, both those used within chunks and those used outside
of chunks, are defined in this section. The
\texttt{@<<fundamental indexing keywords, which are restricted to within a code chunk>>},
index definitions or usages of identifiers and track the definitions of
identifiers in a chunk and the usages of identifiers in a chunk. They
may seem redundant, but are not; the Noweb Hacker's Guide offers a
better explanation of the differences.

<<indexing and cross-referencing set-off words>>=
(define-peg-rule idx ()
  (bol) "@index" spc)
(define-peg-rule xr ()
  (bol) "@xref" spc)

<<fundamental indexing keywords, which are restricted to within a code chunk>>=
(define-peg-rule i-define-or-use ()
  idx
  (substring (or "defn" "use")) spc (substring !eol) nl
  (action
   (unless peg-noweb--parser-within-code-chunk?
             (error "WHYSE parse error: index definition or index usage occurred outside of a code chunk.")))
  `(s1 s2 -- (cons (make-symbol s1) s2)))

<<identifiers defined in a chunk>>
<<identifiers used in a chunk>>

<<identifiers defined in a chunk>>=
(define-peg-rule i-definitions ()
  idx "begindefs" nl
  (list (+ (and (+ i-isused) i-defitem)))
  idx "enddefs" nl
  `(definitions -- (cons 'definitions definitions)))
(define-peg-rule i-isused ()
  idx (substring "isused") spc (substring label) nl
  `(u l -- (cons 'used! l)))
(define-peg-rule i-defitem ()
  idx (substring "defitem") spc (substring !eol) nl
  `(d i -- (cons 'def-item i)))

<<identifiers used in a chunk>>=
(define-peg-rule i-usages ()
  idx "beginuses" nl
  (list (+ (and (+ i-isdefined) i-useitem)))
  idx "enduses" nl
  `(usages -- (cons 'usages usages)))
(define-peg-rule i-isdefined ()
  idx (substring "isdefined" spc label) nl)
(define-peg-rule i-useitem ()
  idx (substring "useitem" spc !eol) nl) ;; !eol :== ident
@

The summary index of identifiers is a file--specific set of keywords.
The index lists all identifiers defined in the file (at least all of
those recognized by the autodefinitions filter).

<<the index of identifiers>>=
(define-peg-rule i-identifiers ()
  idx "beginindex" nl
  (list (+ i-entry))
  idx "endindex" nl
  `(l -- (cons 'i-identifiers l)))
(define-peg-rule i-entry ()
  idx "entrybegin" spc (substring label spc !eol) nl
  (list (+ (or i-entrydefn i-entryuse)))
  idx "entryend" nl
  `(entry-label lst -- (cons 'entry-label lst)))
(define-peg-rule i-entrydefn ()
  idx (substring "entrydefn") spc (substring label) nl
  `(defn label -- (cons 'defn label)))
(define-peg-rule i-entryuse ()
  idx (substring "entryuse") spc (substring label) nl
  `(use lst -- (cons 'use lst)))
@

\texttt{@index nl} was deprecated in Noweb 2.10, and \texttt{@index localdefn}
is not widely used (assumedly) nor well-documented, so it is unsupported by
\texttt{peg-noweb}. Contributions for support might not be accepted, but will be
reviewed; most users should avoid the exotic syntax, I believe. See the Noweb
Hacker's Guide for more information.

<<unsupported indexing keywords>>=
(define-peg-rule i-localdefn ()
  idx "localdefn" spc !eol nl
  (action (error "\"@index localdefn IDENTIFIER_LIST\" was detected during
parsing, indicating unsupported, exotic syntax. Are you Oren Ben-Kiki?
Ramsey wrote in the *Noweb Hacker's Guide* that this was exotic syntax
(presumably) added specifically for that user. Please submit a patch to support
your use case, with argument.")))
;; NOTE: Noweb 2.13 sources include plenty of @index nl, so despite its
;; deprecation it is still around in important documents. TODO: submit a patch
;; to the Noweb 2.13 sources which removes the hand-written definitions and adds
;; a proper call to various autodefinitions filters to recognize identifiers.
(define-peg-rule i-nl ()
  idx "nl" nl
  (action (error "\"@index nl\" detected during parsing, indicating deprected,
hand-written \"@ %%def IDENTIFIER_LIST\" syntax in the Noweb source. This
syntax was deprecated in Noweb 2.10, and is entirely unsupported. Write
an autodefs.LANGUAGE program, which is usually an AWK script, for the
language you are using if not listed in \"noweave -showautodefs\" output.")))
@

\subsection{Cross referencing}

<<cross-referencing keywords>>=
(define-peg-rule x-label ()
  xr (substring "label" spc label) nl
  `(substr -- (cons 'x-label (cadr (split-string substr)))))
(define-peg-rule x-ref ()
  xr (substring "ref" spc label) nl
  `(substr --  (cons 'ref (cadr (split-string substr)))))

;; FIXME: improve the error handling at this point. It is not fragile any
;; longer, because most things are ignored and this is hackish; however, the
;; message reporting is not helpful. It would be nice to have _only_ the chunk
;; name reported, and formatted with @<< and >>.
;;
;; TODO: Reproduction steps: make a reference to an undefined code chunk
;; within another code chunk. For fixing this issue, undefined code
;; chunks should also be referenced within quotations in documentation.
(define-peg-rule x-undefined ()
  xr (or "ref" "chunkbegin") spc
  (guard
   (if (string= "nw@notdef"
                (buffer-substring-no-properties (point) (+ 9 (point))))
       (error (format "%s: %s: %s:\n@<@<%s>>"
                      "WHYSE"
                      "nw@notdef detected"
                      "an undefined chunk was referenced"
                      (buffer-substring-no-properties (progn (forward-line) (point))
                                                      (end-of-line)))))))

(define-peg-rule x-prev-or-next-def ()
  xr (substring (or "nextdef" "prevdef")) spc (substring label) nl
  `(previous-or-next-chunk-defn label -- (cons (make-symbol previous-or-next-chunk-defn) label)))

(define-peg-rule x-continued-definitions-of-the-current-chunk ()
  xr "begindefs" nl
  (list (+ (and xr (substring "defitem") spc (substring label) nl)))
  xr "enddefs" nl)

(define-peg-rule x-usages ()
  xr "beginuses" nl
  (list (+ (and xr "useitem" spc (substring label) nl)))
  xr "enduses" nl)

(define-peg-rule x-notused ()
  xr "notused" spc (substring !eol) nl
  `(name -- (cons 'unused! name)))
(define-peg-rule x-chunks ()
  nwnl
  nwnl
  xr "beginchunks" nl
  (list (+ x-chunk))
  xr "endchunks" nl
  `(l -- (cons 'x-chunks l)))
(define-peg-rule x-chunk ()
  xr "chunkbegin" spc (substring label) spc (substring !eol) nl
  (list (+ (list (and xr
                      (substring (or "chunkuse" "chunkdefn"))
                      `(chunk-usage-or-definition -- (make-symbol chunk-usage-or-definition))
                      spc
                      (substring label)
                      nl))))
  xr "chunkend" nl)

;; Associates label with tag (@xref tag $LABEL $TAG)
(define-peg-rule x-tag ()
  xr "tag" spc label spc !eol nl)
(define-peg-rule label ()
  (+ (or "-" [alnum]))) ;; A label never contains whitespace.

<<error-causing keywords>>=
;; User-errors (header and trailer) and tool-error (fatal)
;; Header and trailer's further text is irrelevant for parsing, because they cause errors.
(define-peg-rule header ()
  (bol) "@header" ;; formatter options
  (action (error "[ERROR] Do not use totex or tohtml in your noweave pipeline.")))
(define-peg-rule trailer ()
  (bol) "@trailer" ;; formatter
  (action (error "[ERROR] Do not use totex or tohtml in your noweave pipeline.")))
(define-peg-rule fatal ()
  (bol) "@fatal"
  (action (error "[FATAL] There was a fatal error in the pipeline. Stash the work area and submit a bug report against Noweb, WHYSE, and other relevant tools.")))
@

\section{Parse Tree Processing}
\label{sec:parse-tree-processing}

The parse tree is a list of noweb documents, each being a list
themselves. The first atom of an inner list, corresonding to a document,
is the filename of that document (hopefully the same filename as passed
on the commmand-line elsewhere when the document is used).

Deeper, each document-list contains as the second atom a list of its
contents, which is an association list thereof. Each association in the
alist is bewteen the symbol relating to the rule that generated the cons
cell, and the contents appropriate to the symbol.

The first step is to ensure the association lists in the parse tree are in a
format that is acceptable to built-in Emacs Lisp functions; this will make it
easier to navigate the tree and transform it. Other texts call this manipulation
of the parse tree ``list destructuring'' (see
\Url{https://www.lispworks.com/documentation/lcl50/loop/loop-47.html}).

Some associations are reductions from the "initial parse tree",
which---thanks to the \textsc{peg} package and \textit{PEG parsing in
  general}---are not reduced after parsing but during and so constitute the
original parse tree as returned by \texttt{peg}. Modifications to the
parsing procedure overall can occur directly without losing information, and
thanks to literate programming should be easy for advanced users.

The "initial parse tree" looks like the one below.

<<example-1>>=
'((noweb-document-one
   ((0 . docs)
    (text . "\tex{} is cool!"))
   ((1 . code)
    (text . "(message \"LISP is awesome!\")")))
  (noweb-document-two
   ((0 . docs)
    (text . "asdf is a system definition format in Common LISP,")
    (nwnl . "\n")
    (text . "and I like to use it."))
   ((1 . code)
    (text . "jkl; is the right-handed corollary of asdf."))
   ((2 . docs)
    (text . "\LaTeX{} is great!"))
   ((3 . docs)
    (text . "Noweb, written by Norman Ramsey is sweet!"))))
@ 

The reductions which occur during parsing make chunk zero of the second
noweb document look like this in the final result.

<<example-2>>=
((0 . code)
 (text . "asdf is a system definition format in Common LISP, and I like to use it."))
@ 

The new result is much easier to use as data for other programs (SQL in
this case). In the verbatim text a literal newline was inserted rather
than retaining the escape sequence, which is exactly what happens in the
reduction step as well. The next subsection discusses the details of how
the reduction in complexity exampled above is achieved.

\subsection{Reducing complexity in the alist}
The first step in making the parse tree navigable for other programs is
collapsing adjacent ``stringy'' tokens into single \texttt{text} tokens. The
output tool syntax of notangle, and the parse tree resulting from the
PEG, (breifly) contain individual text tokens for fragments of whole
text lines and form feed characters. These tokens exist because the
cross-referencing tokens fragment the text lines, and new lines in the
noweb document are treated specially to facilitate this fragmentation.

A small quote from the tool syntax of a development version of \whyse{} is
shown in this example in its parsed form. However, during actual parsing
these adjacent tokens are \textit{immediately collapsed} into singular
tokens.

<<example-3>>=
(text . "  and \textsc{Noweb}'s \texttt{finduses.nw}!")
(nwnl . "@nl")
(text . "\end{enumerate}")
(nwnl . "@nl")
(text . "")
(nwnl . "@nl")
@ 

To collapse these tokens into a single text token the \texttt{peg--stack}
must be manipulated carefully. It isn't advisable to manipulate this
variable in the course of a PEG grammar's actions. There is a use case
for it when the previous rules and actions won't accommodate the
necessary action without refactoring a larger part of the grammar. In
this development version that is not a goal; basic functionality is
sought after, not robustness or beauty, so hacking the desired behaviour
together quickly is better.

TODO: after some testing I have found that the initial form of the parse tree is
not very useful. It is easier to work with the parse tree when some of the
information is implicit, such as the chunk type and number. The chunk type can
be implicitly indicated by using the first element of the association list of a
chunk as its chunk name or nil; documentation chunks don't have names, but they
do belong to LaTeX or HTML sections, so that's something to consider for later.

\begin{verbatim}
((nil "\\documentclass{article}")
 ("example-3" "print(\"Hi, ESS!\")"))
\end{verbatim}

\subsection{Retrieving chunks}
\label{sec:retrieving-chunks}

\texttt{peg-noweb-nth-chunk-of-nth-noweb-document} retrieves the parse tree for the nth
noweb document, which in the case of \texttt{whyse.nw} is the parse tree of
the zeroth-indexed document. It's quite a simple function. To obtain a
given chunk of this document from the parse tree the result of the
function is called with \texttt{nth} and the index of the chunk.

<<define functions>>=
<<functions for navigating noweb tool syntax parse trees>>
@

In this section I define more functions to work on the parse tree of a Noweb
document.

<<functions for navigating noweb tool syntax parse trees>>=
(defun peg-noweb-document (nth-document parse-tree)
  "Return the `nth' document in the parse tree, represented as a list of the documents' name and then its parse subtree."
  (nth nth-document parse-tree))

(defalias 'peg-noweb-filename #'cl-first
  "Return the file name of the DOCUMENT parse tree.")

(defun peg-noweb-chunk (nth-chunk document)
  "Return the subtree for the Nth chunk of a noweb document parse subtree."
  (nth nth-chunk document))

(defun peg-noweb-chunk-attributes (chunk)
  "Return a list of the CHUNK number, type, and name (if it has one)."
  (list (cl-first chunk)
        (if-let* ((name (assq 'chunk chunk)))
            (cdr name))))

(defun peg-noweb-chunk-text (chunk)
  "Join all the strings returned from the collection in the loop,
and return the single string."
  (string-join
   (cl-loop for elt in chunk collect
            (when (and (listp elt) (equal 'text (car elt)))
              (cdr elt)))
   ""))

;; NOTE: deprecated.
(defun peg-noweb--concatenate-text-tokens (new-token)
  "Join the values of two text token associations in a two-element token alist.

If the two associations shouldn't be joined, return them to the stack."
  (prog1
      ;; Concatenation only occurs when the previous token examined was
      ;; a text or nwnl token, ergo there must have been a text or nwnl
      ;; token previously examined for any concatenation to occur. When
      ;; no such token has been examined immediately return the
      ;; (stringy) token recieved and indicate it must have been a
      ;; stringy token by chaning the value of `peg-noweb--first-stringy-token?'
      ;; accordingly. Subsequent runs will then operate on potential
      ;; pairs of stringy tokens.
      (if-let ((not-first-stringy-token? (not peg-noweb--first-stringy-token?))
               (previous-token  (pop peg--stack))
               ;; The previous token cannot be a text or nwnl token if
               ;; it is not a list, and checking prevents causing an
               ;; error by taking the `car' of a non-list token, e.g. the
               ;; filename token.
               (previous-token-is-alist?
                (prog1 (and (listp previous-token)
                            (listp new-token)
                            (or (assoc 'text `(,new-token))
                                (assoc 'nl `(,new-token)))
                            (or (assoc 'text `(,previous-token))
                                (assoc 'nl `(,previous-token)))))))
          ;; Join the association's values and let the caller push a single
          ;; token back onto the `peg--stack'.
          (cons 'text (format "%s%s" (cdr previous-token)
                              (cdr new-token)))

        ;; Push the previous token back to the `peg--stack', and let the
        ;; caller push the new token to that stack.
        (push previous-token peg--stack)
        new-token)
    (when peg-noweb--first-stringy-token? (setq peg-noweb--first-stringy-token? nil))))

(defun peg-noweb-document-deparse (document)
  "Deparse DOCUMENT to produce its markup representation."
  (let* ((x (cl-loop for chunk in (cl-rest document)
                     when chunk collect
                     (let* ((cons-cell (or (rassq 'code chunk)
		                                       (rassq 'docs chunk)))
                            (i (car cons-cell))
	                          (kind (symbol-name (cdr cons-cell)))
	                          (name (cdr (assq 'chunk chunk))))
                       (string-join (flatten-list (list (format "@%s %s %d" "begin" kind i)
                                                        (if (string= kind "code")
	                                                          (format "@defn %s" (if name name "")))
                                                        (peg-noweb-chunk-deparse-contents chunk)
                                                        (format "@%s %s %d" "end" kind i)))
                                    "\n"))
                     into X
                     finally return X))
         (y (cons (format "@file %s" (cl-first document)) x))
         (z (string-join y "\n")))
    (concat z "\n")))
@

The following function is deprecated, but is included because I don't want to
delete it now nor resurrect it later with Git.

<<functions for navigating noweb tool syntax parse trees>>=
(defun peg-noweb-chunk-deparse-contents-text (text)
  (cl-loop for line in (string-split text "\n") collect
           (if (string-empty-p line)
	             "@nl"
             (format "@text %s\n@nl" line))
           into x finally return (string-join x "\n")))
@

This function is not deprecated, however. It is very much current.

<<functions for navigating noweb tool syntax parse trees>>=
(defun peg-noweb-chunk-deparse-contents (chunk)
  (cl-loop
   for (k . v) in (cdr chunk) while k collect
   (cl-case k
     ((text defn) (format "@%s %s" (symbol-name k) v))
     (nl "@nl")
     (quotation (format "@quote\n%s@endquote" v))
     (index (format "@index %s" v))
     (use (format "@use %s" v)))))
@

\section{Emacs LISP autodefinitions}
\label{sec:emacs-lisp-definitions}

The built-in package \texttt{PEG} greatly simplifies the source code of this
package: rather than relying on an autodefs.elisp file written in AWK we can use
PEG parsing to manage Emacs LISP definitions when we see them. The following
PEXs are based off the AWK code written by Joseph S. Riel.

The following grammar should be parameterizable using an Emacs LISP
customization varible which allows users to list the symbols of functions and
macros which define things. For example, \texttt{define-peg-rule} and
\texttt{define-peg-ruleset} define PEG-related things, but when peg-noweb is
parsing a noweb with emacs lisp which defines peg rules and rulesets the
identifiers defined with these functions or macros would not be marked up
properly. Therefore, at least within Emacs, we can use Emacs LISP to mark up
Noweb texts with the necessary @defn options PEG parsing rather than regular
expressions in AWK.

<<Emacs-LISP-autodefinitions.peg.el>>=
;; Derived from AWK code released under the GNU GPL v2 license by Joseph S. Riel;
;; that code is Copyright (c) 2005-2015 by Joseph S. Riel.  All rights reserved.
(whitespace (+ (or " " "\t")))
(identifier; FIXME: the `action' is not valid; it must insert the matched text into the stream as below.
 (substring (+ (not (or " " "\t" "\n" "()"))))
 (action (insert (string-join `("@index" "defn" peg--stack)))))
(defxxx (or "defun"
            "defvar"
            "defconst"
            "defgroup"
            "defalias"
            "defsubst"
            "defmacro"
            "defcustom"
            "defadvice"
            "defimage"))
(define (or "define-minor-mode"
            "define-derived-mode"
            "define-abbrev"
            "define-category"
            "define-prefix-command"
            "define-key-after"))
(definitions (bol) "@text" whitespace
             (or defxxx define) whitespace
             ;; FIXME: `identifier' is not a variable containing the matched
             ;; substring. TODO: insert `@defn', and replace `@text' so that it
             ;; remains.
             (replace (substring identifier) identifier)
             (eol) "\n")
@ 


\end{document}


% Local Variables:
% mode: poly-noweb
% poly-noweb-innermode: emacs-lisp-mode
% noweb-code-mode: emacs-lisp-mode
% End:
